import os
import streamlit as st
from dotenv import load_dotenv
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹å·¥å…·
from src.models import get_model

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŒæ¨¡å‹èŠå¤©æœºå™¨äºº",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

if "memory" not in st.session_state:
    st.session_state.memory = None
    
if "model_name" not in st.session_state:
    st.session_state.model_name = "é€šä¹‰åƒé—®"  # é»˜è®¤ä½¿ç”¨é€šä¹‰åƒé—®

# é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– åŒæ¨¡å‹èŠå¤©æœºå™¨äºº")

# ä¾§è¾¹æ  - æ¨¡å‹é€‰æ‹©
with st.sidebar:
    st.header("è®¾ç½®")
    model_name = st.selectbox(
        "é€‰æ‹©æ¨¡å‹", 
        ["é€šä¹‰åƒé—®", "DeepSeek"],  # é€šä¹‰åƒé—®åœ¨å‰
        index=0
    )
    
    # æ›´æ–°æ¨¡å‹é€‰æ‹©
    if model_name != st.session_state.model_name:
        st.session_state.model_name = model_name
        # åˆ‡æ¢æ¨¡å‹æ—¶é‡ç½®è®°å¿†
        st.session_state.memory = None
        
    # æ·»åŠ è®°å¿†é•¿åº¦æ§åˆ¶
    max_messages = st.slider("ä¿ç•™å¯¹è¯è½®æ•°", min_value=1, max_value=10, value=5)
    
    # æ·»åŠ æ¸…é™¤ä¼šè¯æŒ‰é’®
    if st.button("æ¸…é™¤ä¼šè¯"):
        st.session_state.messages = []
        st.session_state.memory = None
        st.rerun()

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message("user"):
            st.write(message["content"])
    else:
        with st.chat_message("assistant"):
            st.write(message["content"])

# æ„å»ºç³»ç»Ÿæç¤ºè¯
system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å¥½ä¸”æœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚
è¯·ç›´æ¥å›ç­”é—®é¢˜ï¼Œä¿æŒå›ç­”ç®€æ´æ˜äº†ã€‚
å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œè¯·è¯šå®åœ°è¯´å‡ºæ¥ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚
ä¸è¦åœ¨å›ç­”ä¸­ä½¿ç”¨{input}æˆ–{output}è¿™æ ·çš„å­—ç¬¦ã€‚"""

# åˆ›å»ºç›´æ¥çš„æç¤ºæ¨¡æ¿ï¼Œé¿å…ä½¿ç”¨å¤æ‚çš„æ ¼å¼åŒ–
prompt_template = f"{system_prompt}\n\n"

# è·å–ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜...")

if user_input:
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    with st.chat_message("user"):
        st.write(user_input)
    
    # è·å–æ¨¡å‹
    llm = get_model(st.session_state.model_name)
    
    # ç”Ÿæˆå›ç­”
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                # å¤„ç†å†å²è®°å½• - æ§åˆ¶å†å²é•¿åº¦ï¼Œåªä¿ç•™æœ€è¿‘çš„å¯¹è¯
                max_pairs = max_messages  # ä»ä¾§è¾¹æ çš„æ»‘å—è·å–å€¼
                recent_messages = st.session_state.messages[-min(len(st.session_state.messages), max_pairs*2-1):-1]
                
                # æ„å»ºå®Œæ•´æç¤ºæ–‡æœ¬
                full_prompt = prompt_template
                
                # æ·»åŠ å†å²æ¶ˆæ¯
                for msg in recent_messages:
                    prefix = "ç”¨æˆ·: " if msg["role"] == "user" else "åŠ©æ‰‹: "
                    full_prompt += f"{prefix}{msg['content']}\n"
                
                # æ·»åŠ å½“å‰é—®é¢˜
                full_prompt += f"ç”¨æˆ·: {user_input}\nåŠ©æ‰‹: "
                
                # ç›´æ¥è°ƒç”¨æ¨¡å‹
                response = llm.invoke(full_prompt)
                
                # æå–å“åº”å†…å®¹
                response_text = response.content
                
                # æ£€æŸ¥å›å¤ä¸­æ˜¯å¦åŒ…å«å ä½ç¬¦ï¼Œå¦‚æœæœ‰åˆ™æ›¿æ¢
                if "{input}" in response_text:
                    response_text = response_text.replace("{input}", user_input)
                if "{output}" in response_text:
                    response_text = response_text.replace("{output}", "")
                
                # æ˜¾ç¤ºå›ç­”
                st.write(response_text)
                
                # ä¿å­˜åŠ©æ‰‹å›ç­”åˆ°å†å²
                st.session_state.messages.append({"role": "assistant", "content": response_text})
                
                # åˆå§‹åŒ–æˆ–æ›´æ–°è®°å¿†
                if st.session_state.memory is None:
                    st.session_state.memory = ConversationBufferMemory(
                        return_messages=True,
                        memory_key="history"
                    )
                
                # æ›´æ–°è®°å¿†
                st.session_state.memory.chat_memory.add_user_message(user_input)
                st.session_state.memory.chat_memory.add_ai_message(response_text)
                
            except Exception as e:
                st.error(f"ç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                st.write("æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åå†è¯•ã€‚")
                st.session_state.messages.append({"role": "assistant", "content": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åå†è¯•ã€‚"}) 